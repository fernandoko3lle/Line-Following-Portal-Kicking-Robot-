# Lineâ€‘Following Portalâ€‘Kicking Robot ğŸ¤–ğŸ
**RobÃ³tica Computacional â€“ Final Project (2023.2)**  
*Author â€“ Fernando Ganzer Koelle*

---

## 1â€¯Â·â€¯Project Summary
This repo hosts the code and Gazebo assets for a **fullyâ€‘autonomous differentialâ€‘drive robot** that:

1. Locks onto a **colourâ€‘coded line** (blue at the start, pink halfway).  
2. **Completes a full lap** of the track, returning to the starting point.  
3. **Detects every yellow â€œportalâ€** along the way and knocks it over with a fast arm swing.  
4. **Stops automatically** once the loop is done.

Built on **ROSÂ Noetic** (UbuntuÂ 20.04) for the *Computational Robotics* course at **Insper University**.

---

## 2â€¯Â·â€¯Key Features

|Â #Â | Capability | Stack / Algorithm |
|:-:|------------|-------------------|
|Â 1Â | Finiteâ€‘State Machine (search â†’ track line â†’ kick portal â†’ finish) | `rospy`, custom dispatcher |
|Â 2Â | Dualâ€‘colour line tracking (blueâ€¯â†’â€¯pink) | HSV thresholdingÂ + centroid steering |
|Â 3Â | Yellow portal detection & knockâ€‘down | Colour maskÂ + arm actuation (`Float64`) |
|Â 4Â | Simâ€‘toâ€‘real with one cameraâ€‘calibration switch | RealSense intrinsics YAML |

---

## 3â€¯Â·â€¯Repository Layout
```
pf-robcomp-23b-ex3/          â† Catkin package (drop in catkin_ws/src)
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ package.xml
â””â”€â”€ scripts/
    â”œâ”€â”€ q3.py                â˜… Main FSM / navigation node
    â””â”€â”€ â€¦                    Helper modules
pista.png                    Track schematic (blueâ†’pink, yellow portals)
README.md                    â† you are here
```

---

## 4â€¯Â·â€¯QuickÂ Start

### 4.1â€¯Prerequisites
* **UbuntuÂ 20.04** + **ROSÂ Noetic desktopâ€‘full**
* GazeboÂ 11 (bundled with desktopâ€‘full)
* PythonÂ 3.8, `opencv-python`, `numpy`, `cv_bridge`, `sensor_msgs`, `geometry_msgs`

### 4.2â€¯Build
```bash
# inside your catkin workspace
cd ~/catkin_ws/src
git clone https://github.com/<yourâ€‘user>/portalâ€‘kickerâ€‘robot.git
cd ..
rosdep install --from-paths src --ignore-src -r -y
catkin_make
source devel/setup.bash
```

### 4.3â€¯Run (simulation)
```bash
roslaunch my_simulation corrida_de_obstaculos.launch &   # Gazebo world + RViz
roslaunch mybot_description mybot_control2.launch   &   # bring up arm controller
rosrun pf-robcomp-23b-ex3 q3.py                       # autonomous brain
```

### 4.4â€¯Run (real robot)
```bash
rosparam load config/camera_intrinsics_realsense.yaml /camera
rosrun pf-robcomp-23b-ex3 q3.py
```

---

## 5â€¯Â·â€¯Results
* âœ… **Lap success:** 100â€¯% (10/10 sim runs)  
* âš¡ **Portals knocked:** 8â€¯/â€¯8 per lap  
* ğŸ¥ **Demo:** <https://youtu.be/NYXu_f0AthM>

---

## 6â€¯Â·â€¯How it Works
<details>
<summary>Stateâ€‘machine diagram</summary>

```mermaid
graph LR
  IDLE -->|start| SEARCH
  SEARCH -->|see line| FOLLOW
  FOLLOW -->|portal detected| KICK
  KICK --> FOLLOW
  FOLLOW -->|lap done| STOP
```
</details>

---

## 7â€¯Â·â€¯RoadmapÂ /Â TODO
- [ ] Split imageâ€‘processing into standalone ROS nodes  
- [ ] Add GitHubâ€¯Actions CI (`rostest`)  
- [ ] Provide Docker image for oneâ€‘command demo  

---

## 8â€¯Â·â€¯License
MITÂ License â€” see `LICENSE`.

---

## 9â€¯Â·â€¯Acknowledgements
Developed for *Computational Robotics* @ **Insper University** â€” thanks to Prof.â€¯RodolfoÂ Braga and the teaching staff for guidance and assets.

---

> *Open to issues and pull requests!* ğŸš€
